{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing.dummy import Pool\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import random\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(url, index_exchange):\n",
    "    \"\"\"\n",
    "    Function to fetch stock information from a specified URL of the traderfox.de website\n",
    "    with an specified index / exchange\n",
    "\n",
    "    Inputs:\n",
    "        url (str): one of the available urls from traderfox.de\n",
    "        index_exchange (str): name of the index / exchnage from which\n",
    "            the stocks should be selected\n",
    "    \"\"\"\n",
    "    browser =  webdriver.Firefox()\n",
    "    time.sleep(2)\n",
    "    browser.get(url)\n",
    "    time.sleep(5)\n",
    "    soup = BeautifulSoup(browser.page_source,\"html\")\n",
    "    time.sleep(5)\n",
    "    names = []\n",
    "    Row = soup.find('table', attrs = {'id' : 'insert-stocks'})\n",
    "    for name in Row.find_all('td', attrs = {'class' : 'name'}):\n",
    "            try:\n",
    "                names.append(name.text)\n",
    "            except:\n",
    "                names.append(\"\")\n",
    "\n",
    "    wkns = []\n",
    "    Row = soup.find('table', attrs = {'id' : 'insert-stocks'})\n",
    "    for wkn in Row.find_all('td', attrs = {'data-id' : 'wkn'}):\n",
    "            try:\n",
    "                wkns.append(wkn.text)\n",
    "            except:\n",
    "                wkns.append(\"\")\n",
    "\n",
    "    FRAME = pd.DataFrame.from_dict(\n",
    "            {'name': names,\n",
    "            'wkn': wkns,\n",
    "            'index' : index_exchange\n",
    "            })\n",
    "    time.sleep(1)\n",
    "    browser.quit()\n",
    "    return(FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_ls = [\"https://traderfox.de/aktien/alle-amex-aktien-bestandteile\"]#\"https://traderfox.de/aktien/alle-nasdaq-aktien-bestandteile\"]#]\n",
    "#  \"https://traderfox.de/aktien/alle-nyse-aktien-bestandteile\"]#,\n",
    "   # \"https://traderfox.de/aktien/deutschland-160-bestandteile\",\n",
    "   # \"https://traderfox.de/aktien/alle-nyse-aktien-bestandteile\",\n",
    "  #  \"https://traderfox.de/aktien/alle-nasdaq-aktien-bestandteile\",\n",
    "#]\n",
    "#https://traderfox.de/aktien/stoxx-europe-600-bestandteile\n",
    "country_names_ls = [\"AMEX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_frame = pd.DataFrame({})\n",
    "for i, url in enumerate(url_ls):\n",
    "    df = get_stock_data(url, country_names_ls[i])\n",
    "    ticker_frame = ticker_frame.append(df)\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker(initial_frame):\n",
    "    url_ticker = \"https://www.finanznachrichten.de/\"\n",
    "    url_yf_ticker = \"https://finance.yahoo.com/quote/FB?p=FB\"\n",
    "    browser =  webdriver.Firefox()\n",
    "    extension_path = r\"C:\\Users\\Jonathan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\wl4weym2.default-1633941918487\\extensions\\jid1-MnnxcxisBPnSXQ@jetpack.xpi\"\n",
    "    browser.install_addon(extension_path, temporary=True)\n",
    "    time.sleep(2)\n",
    "    browser.get(\"about:support\")\n",
    "    time.sleep(5)\n",
    "    browser.get(url_ticker)\n",
    "    time.sleep(20)\n",
    "    #clear = WebDriverWait(browser, 5).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div/div[2]/div[3]/div[2]/button\"))).click()\n",
    "    time.sleep(1)\n",
    "    ticker = []\n",
    "    de_ticker = []\n",
    "    industry = []\n",
    "    ISIN = []\n",
    "    for i, wkn in enumerate(initial_frame.wkn):\n",
    "        print(len(de_ticker), len(industry), len(ISIN))\n",
    "        # if wkn not valid\n",
    "        if wkn == \"-\":\n",
    "            de_ticker.append(\"not_found\")\n",
    "            industry.append(\"not_found\")\n",
    "            ISIN.append(\"not_found\")\n",
    "            continue\n",
    "        try:\n",
    "            clear = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#fnk-suche-eingabe\"))).clear()\n",
    "            time.sleep(3)\n",
    "            search = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#fnk-suche-eingabe\")))\n",
    "            time.sleep(1)\n",
    "            search.send_keys(str(wkn))\n",
    "            time.sleep(3)\n",
    "            browser.find_element_by_css_selector('#suchhilfeListe > tbody:nth-child(2) > tr:nth-child(3) > td:nth-child(2)').click()\n",
    "            time.sleep(random.randint(3,5))\n",
    "            de_ticker.append(str(WebDriverWait(browser, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#produkt-ticker\"))).text.replace(\"Ticker-Symbol: \", \"\").lstrip()))\n",
    "            #time.sleep(2)\n",
    "        except:\n",
    "            de_ticker.append(\"not_found\")\n",
    "            industry.append(\"not_found\")\n",
    "            ISIN.append(\"not_found\")\n",
    "            continue\n",
    "        try:\n",
    "            industry.append(str(WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".a > a:nth-child(2)\"))).text))\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            industry.append(\"not_found\")\n",
    "        try:\n",
    "            ISIN.append(str(WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#produkt-isin\"))).text.replace(\"ISIN: \", \"\").lstrip()))\n",
    "            time.sleep(1)\n",
    "            #time.sleep(random.randint(2,4))\n",
    "        except:\n",
    "            ISIN.append(\"not_found\")\n",
    "\n",
    "\n",
    "        if i % 4 == 0:\n",
    "            try:\n",
    "                browser.refresh()\n",
    "                time.sleep(4)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    #check if lengths are equal   \n",
    "    print(len(industry), len(ISIN), len(de_ticker))\n",
    "    try:\n",
    "        browser.get(url_yf_ticker)\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        browser.get(url_yf_ticker)\n",
    "        time.sleep(5)\n",
    "    try:\n",
    "        browser.find_element_by_css_selector(\"#scroll-down-btn\").click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        browser.find_element_by_css_selector(\"button.btn:nth-child(5)\").click()\n",
    "        time.sleep(4)\n",
    "    except:\n",
    "        pass\n",
    "    for _ISIN in ISIN:\n",
    "        if _ISIN == \"not_found\":\n",
    "            ticker.append(\"not_found\")\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "        #check again for popup and scroll\n",
    "        try:\n",
    "            browser.find_element_by_css_selector(\"#scroll-down-btn\").click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            browser.find_element_by_css_selector(\"button.btn:nth-child(5)\").click()\n",
    "            time.sleep(4)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        clear = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#yfin-usr-qry\"))).clear()\n",
    "        #time.sleep(1)\n",
    "        try:\n",
    "            search = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#yfin-usr-qry\")))\n",
    "            #time.sleep(1)\n",
    "            search.send_keys(str(_ISIN))\n",
    "            time.sleep(2)\n",
    "            ticker.append(str(WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#result-quotes-0 > div.modules_quoteLeftCol__gkCSv.modules_Ell__77DLP.modules_IbBox__2pmLe > div.modules_quoteSymbol__hpPcM.modules_Ell__77DLP.modules_IbBox__2pmLe\"))).text))\n",
    "        except:\n",
    "            ticker.append(\"not_found\")\n",
    "            \n",
    "    print(len(ticker))      \n",
    "\n",
    "    frame = pd.DataFrame.from_dict(\n",
    "        {\"name\" : initial_frame.name,\n",
    "        \"wkn\" : initial_frame.wkn,\n",
    "        \"index\" : \"AMEX\",\n",
    "        'de_ticker' : de_ticker,\n",
    "        'ticker': ticker,\n",
    "        'industry': industry,\n",
    "        'ISIN': ISIN\n",
    "        })\n",
    "    time.sleep(1)\n",
    "    browser.quit()\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ticker_amex = get_ticker(ticker_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ticker_amex.to_csv(\"AMEX_Stocks.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-nasdaq 100\n",
    "\n",
    "-nyse\n",
    "\n",
    "-de\n",
    "\n",
    "-Eurostoxx600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame1 = pd.read_csv(r\"C:\\Users\\Jonathan\\Documents\\GitHub\\finance_Versuchskaninchen\\fama_french\\scraper\\NASDAQStocks_p1.csv\")\n",
    "# frame2 = pd.read_csv(r\"C:\\Users\\Jonathan\\Documents\\GitHub\\finance_Versuchskaninchen\\fama_french\\scraper\\NASDAQ_Stocks1197-2000.csv\")\n",
    "# frame3 = pd.read_csv(r\"C:\\Users\\Jonathan\\Documents\\GitHub\\finance_Versuchskaninchen\\fama_french\\scraper\\NASDAQ_Stocks2000-rest.csv\")\n",
    "\n",
    "# total_frame = pd.concat([frame1, frame2, frame3])\n",
    "# total_frame.to_csv(\"NASDAQ_all_Stocks.csv\", encoding= 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ticker(path):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to update the stock information for the different exchanges / indicies\n",
    "    This function is usefull to:\n",
    "        - check if info is up to date\n",
    "        - after adding new stocks to the {exchange / index}Stocks.csv files\n",
    "        - to check that scraping was not corruped by bad internet connection or other issues\n",
    "        - to validate the scraping\n",
    "    \n",
    "    Inputs:\n",
    "        path (str): path of the file for which to perform the validation\n",
    "\n",
    "    \"\"\"\n",
    "    url_ticker = \"https://www.finanznachrichten.de/\"\n",
    "    url_yf_ticker = \"https://finance.yahoo.com/quote/FB?p=FB\"\n",
    "    # browser =  webdriver.Firefox(executable_path='/home/jonathan/Schreibtisch/geckodriver')\n",
    "    # extension_path = r\"/home/jonathan/.mozilla/firefox/5xapxbqn.default-release/extensions/jid1-MnnxcxisBPnSXQ@jetpack.xpi\"\n",
    "    # browser.install_addon(extension_path, temporary=True)\n",
    "\n",
    "\n",
    "    browser =  webdriver.Firefox()\n",
    "    extension_path = r\"C:\\Users\\Jonathan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\wl4weym2.default-1633941918487\\extensions\\jid1-MnnxcxisBPnSXQ@jetpack.xpi\"\n",
    "    browser.install_addon(extension_path, temporary=True)\n",
    "    time.sleep(2)\n",
    "    #extension_path = r\"C:\\Users\\Jonathan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\wl4weym2.default-1633941918487\\extensions\\firefox-webext@zenmate.com.xpi\"\n",
    "    #browser.install_addon(extension_path, temporary=True)\n",
    "    browser.maximize_window()\n",
    "    browser.get(\"about:support\")\n",
    "    time.sleep(5)\n",
    "    browser.get(url_ticker)\n",
    "    time.sleep(5)\n",
    "    file = pd.read_csv(path, encoding='utf-8')\n",
    "    try:\n",
    "        file.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        file.drop('Unnamed: 0.1', axis = 1, index = True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, row in file.iterrows():\n",
    "        if (row.ISIN) == \"not_found\" and (row.wkn != \"-\"):\n",
    "            print(file.loc[i, \"name\"])\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                clear = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#fnk-suche-eingabe\"))).clear()\n",
    "                time.sleep(random.randint(3,4))\n",
    "                search = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#fnk-suche-eingabe\")))\n",
    "                time.sleep(random.randint(2,3))\n",
    "                search.send_keys(str(row.wkn))\n",
    "                time.sleep(3)\n",
    "                browser.find_element_by_css_selector('#suchhilfeListe > tbody:nth-child(2) > tr:nth-child(3) > td:nth-child(2)').click()\n",
    "                time.sleep(random.randint(2,3))\n",
    "                file.at[i, \"de_ticker\"] = (WebDriverWait(browser, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#produkt-ticker\"))).text.replace(\"Ticker-Symbol: \", \"\").lstrip())\n",
    "                #time.sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if file.at[i, \"industry\"] == \"not_found\":\n",
    "                    file.at[i, \"industry\"] = (WebDriverWait(browser, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".a > a:nth-child(2)\"))).text)\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if file.at[i, \"ISIN\"] == \"not_found\":\n",
    "                    file.at[i, \"ISIN\"] = (WebDriverWait(browser, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#produkt-isin\"))).text.replace(\"ISIN: \", \"\").lstrip())\n",
    "                    time.sleep(random.randint(2,3))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    time.sleep(3)\n",
    "    browser.get(url_yf_ticker)\n",
    "    time.sleep(15)\n",
    "    try:\n",
    "        browser.find_element_by_css_selector(\"#scroll-down-btn\").click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        browser.find_element_by_css_selector(\"button.btn:nth-child(5)\").click()\n",
    "        time.sleep(4)\n",
    "    except:\n",
    "        pass\n",
    "    for i, row in file.iterrows():\n",
    "        if row.ISIN == \"not_found\":\n",
    "            continue\n",
    "        if file.at[i, \"ticker\"] == \"not_found\":\n",
    "            time.sleep(random.randint(1,2))\n",
    "            try:\n",
    "                browser.find_element_by_css_selector(\"#scroll-down-btn\").click()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                browser.find_element_by_css_selector(\"button.btn:nth-child(5)\").click()\n",
    "                time.sleep(4)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            clear = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#yfin-usr-qry\"))).clear()\n",
    "            time.sleep(random.randint(3,5))\n",
    "            try:\n",
    "                search = WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#yfin-usr-qry\")))\n",
    "                time.sleep(1)\n",
    "                search.send_keys(str(row.ISIN))\n",
    "                time.sleep(5)\n",
    "                file.at[i, \"ticker\"] = (WebDriverWait(browser, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#result-quotes-0 > div.modules_quoteLeftCol__gkCSv.modules_Ell__77DLP.modules_IbBox__2pmLe > div.modules_quoteSymbol__hpPcM.modules_Ell__77DLP.modules_IbBox__2pmLe\"))).text)\n",
    "            except:\n",
    "                pass\n",
    "    #exchange = file.index[0]\n",
    "    file.to_csv(\"val_\" + path) \n",
    "\n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ticker(\"val_AMEX_Stocks.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae004d2840ceac983a7d06d3a7778ed5b391f699d527375f584c8006e1f0288f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
